# -*- coding: utf-8 -*-
"""Transfer Learning for Image Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/transfer-learning-for-image-classification-cf5ccaf1-b46e-46c7-be32-f7789cdab2bd.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241004/auto/storage/goog4_request%26X-Goog-Date%3D20241004T052052Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7ff5c909061af653c7ae40112449ccb6371b4acec096b592306c7eedb2b59651658bc56490abe4702eacf0e07c9c9a9b31f8777fea13f2f7f2231b88c8e1c2f47af7c99e04b5285685801c7a0ff8586b363031a01ba64a750f6544c3e25a468756c591c6e02279bbc73860ca968ecbb8f50d1763fb1483792b7e1893eb08bee853a4be8642553548f923910bd0777104dc4d9108e17c659a5303a48b906ccda0e15f6b84e949d7cc889e9abefbfaac55fa7efeaf26aa5b87a0f0110294bd4ce484981015d2a33435bf8b84338d23f3aa070a0c3fc9811e674da715871fb4ca2cebeb72a7bcff49f4fb4a4354c9cda4bf449e8a726ac4b4348e80755ddfce9ef7
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'keras-pretrained-models:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2798%2F7251%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241004%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241004T052051Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da2d98e7a2a841b8daf568e8a2654830d4aba69ac1b98f47c74a4089253927e9233e7575cd36b19ecce524057c2ca56755170e9d3d6f8103b2d251cc611f8470d7ecc69e65326c1e60c41e89567aa813329390296b845338bcdb8ba7bf5c249d04a60387748150caa492ee1e07e03c02a5c54475e9a27801f115ecebab796ebf8470430b79d8d63982e46ce751f36b97069032c2baf7c293883e28ab0a29d7a893e2e4e3fc04345ef6cdec54a84d3cc98e62e03e7d7db86fcf9c1b9b7a6760d8e07f41876e2d851a8652202568be77c0c42f0e92564fead1c8c5d6bd4c262a960e265ba550c8ddcce5e2c09efb953a103ada2ca2dc70ba0f0544e0ca08f0f060e,logos-bk-kfc-mcdonald-starbucks-subway-none:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F106662%2F254150%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241004%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241004T052051Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db7517ce3f58a019372deb3fbe30ff9551b76194624afcbb1fb4a3e76479c90e38b83eb630058a3dccfd33b2d699a4dbc1c8e16073803b9f24808602e32c3913dd7808d0d2c39e23db4f0cc1dda75a536d6bcb89795247eb9bb85ae465a994465525b5e9d9ed5a1a577e44912fe69ff715c6c113ccaf5509becd367d5c22de2413dc182a070a93511e64ade88e5ed88ba51bec5ff2f14eb3e17e6297b8b34eaf2395e14cf8d25e888198a25b7ab3add726faaca13a88f3b346fa4a95426702aabac0688ff75b0e9fe06c3820d2481a8a55ad4868b925e4feb857f9097680dc4e4e9503e5221025ae6cd9786de963ec70b6906c9b97f3bbd3e078cd5af4d28e9bb'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import psutil
import humanize
import os
from IPython.display import display_html



import numpy as np
import pandas as pd



import os
print(os.listdir("../input"))
dataDirectory= "../input/logos-bk-kfc-mcdonald-starbucks-subway-none/logos_v3_mini/logos3"
print(os.listdir(dataDirectory))

print(os.listdir("../input"))

"""To  transfer learning, we first need to download pre-trained model and its weights. To do so:
* First from the right tool bar click "**+Add Data**" button.
* Then search for "**Keras Pretrained Models**" and and add it to your notebook
* Last run the below code to copy the necessary files into "**Keras**" directory where the notebook will use.
"""

!rm -r ~/.keras
!mkdir ~/.keras
!mkdir ~/.keras/models
# not enough space for both
#!cp ../input/keras-pretrained-models/* ~/.keras/models/
#!cp ../input/vgg19/* ~/.keras/models
!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/
!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/
#!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/

import numpy as np
import keras
from keras import backend as K
from keras.models import Sequential
from keras.models import Model
from keras.layers import Activation
from keras.layers import Dense, Flatten # Changed the import to reflect the updated Keras structure
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator # Changed the import to reflect the updated Keras structure
from keras.layers import BatchNormalization # Changed the import to reflect the updated Keras structure
from keras.layers import Dropout # Changed the import to reflect the updated Keras structure
from keras.layers import Conv2D # Changed the import to reflect the updated Keras structure
from keras.callbacks import ModelCheckpoint
from keras.applications.inception_v3 import InceptionV3 # Changed InceptionV to InceptionV3

"""# Paths to data"""

train_path = dataDirectory+'/train'
test_path  = dataDirectory+'/test'
print(os.listdir(train_path))
print(os.listdir(test_path))

"""# Define Image Data Generators for train, validation & test data
tf.keras.preprocessing.image.ImageDataGenerator:

https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator

https://keras.io/preprocessing/image/

Generate minibatches of image data with real-time data augmentation.
The data will be looped over (in batches).

## Arguments:

### validation_split:
Float. Fraction of images reserved for validation (strictly between 0 and 1).

### featurewise_center:
set input mean to 0 over the dataset.

### samplewise_center:
set each sample mean to 0.

### featurewise_std_normalization:
divide inputs by std of the dataset.

### samplewise_std_normalization:
divide each input by its std.

### zca_whitening:
apply ZCA whitening.

### zca_epsilon:
epsilon for ZCA whitening. Default is 1e-6.

### rotation_range:
degrees (0 to 180).

### width_shift_range:
fraction of total width, if < 1, or pixels if >= 1.

### height_shift_range:
fraction of total height, if < 1, or pixels if >= 1.

### shear_range:
shear intensity (shear angle in degrees).

### zoom_range:
amount of zoom. if scalar z, zoom will be randomly picked in the range [1-z, 1+z]. A sequence of two can be passed instead to select this range.

etc...


"""

train_datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        fill_mode='nearest',
    validation_split=0.2) # set validation split

"""# Data generators with flow from directory

flow_from_directory

https://keras.io/preprocessing/image/

Takes the path to a directory & generates batches of augmented data.

## Arguments

### directory:
Path to the target directory. It should contain *** one subdirectory per class ***. Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator. See this script for more details.

### target_size:
Tuple of integers (height, width), default: (256, 256). The dimensions to which all images found will be resized.

### color_mode:
One of "grayscale", "rbg", "rgba". Default: "rgb". Whether the images will be converted to have 1, 3, or 4 channels.

### classes:
Optional list of class subdirectories (e.g. ['dogs', 'cats']). Default: None. ***If not provided, the list of classes will be automatically inferred from the subdirectory names/structure under directory, where each subdirectory will be treated as a different class*** (and the order of the classes, which will map to the label indices, will be alphanumeric). The dictionary containing the mapping from class names to class indices can be obtained via the attribute class_indices.

### class_mode:
One of "categorical", "binary", "sparse", "input", or None. Default: "categorical". Determines the type of label arrays that are returned:
"categorical" will be 2D one-hot encoded labels,
"binary" will be 1D binary labels, "sparse" will be 1D integer labels,
"input" will be images identical to input images (mainly used to work with autoencoders).
If None, no labels are returned (the generator will only yield batches of image data, which is useful to use with model.predict_generator(),  model.evaluate_generator(), etc.). Please note that in case of class_mode None, the data still needs to reside in a subdirectory of directory for it to work correctly.

### batch_size:
Size of the batches of data (default: 32).

### shuffle:
Whether to shuffle the data (default: True)

### seed:
Optional random seed for shuffling and transformations.

### save_to_dir:
None or str (default: None). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).

### save_prefix:
Str. Prefix to use for filenames of saved pictures (only relevant if save_to_dir is set).

### save_format:
One of "png", "jpeg" (only relevant if save_to_dir is set). Default: "png".

### follow_links:
Whether to follow symlinks inside class subdirectories (default: False).

### subset:
Subset of data ("training" or "validation") if *** validation_split *** is set in ImageDataGenerator.

### interpolation:
Interpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are "nearest", "bilinear", and "bicubic". If PIL version 1.1.3 or newer is installed, "lanczos" is also supported. If PIL version 3.4.0 or newer is installed,  "box" and "hamming" are also supported. By default, "nearest" is used.

### Returns

A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.

## Load data from directory

### Select classes by name
"""

#['Burger King','HD Iskender','Kahve Dunyasi', 'KFC','McDonalds','Other', 'Ozsut','Popeyes',  'Starbucks', 'Subway', 'Tavuk Dunyasi']
selectedClasses = ['Burger King', 'KFC','McDonalds','Other', 'Starbucks', 'Subway']

"""### Load images from the selected directories"""

batchSize=32


train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224, 224),
    batch_size=batchSize,
    classes=selectedClasses,
    subset='training') # set as training data

validation_generator = train_datagen.flow_from_directory(
    train_path, # same directory as training data
    target_size=(224, 224),
    batch_size=batchSize,
    classes=selectedClasses,
    subset='validation') # set as validation data

test_generator = ImageDataGenerator().flow_from_directory(
    test_path,
    target_size=(224,224),
    classes=selectedClasses,
    shuffle= False,
    batch_size = batchSize)# set as test data

"""### Number of samples of each class in all data generators"""

print ("In train_generator ")
for cls in range(len (train_generator.class_indices)):
    print(selectedClasses[cls],":\t",list(train_generator.classes).count(cls))
print ("")

print ("In validation_generator ")
for cls in range(len (validation_generator.class_indices)):
    print(selectedClasses[cls],":\t",list(validation_generator.classes).count(cls))
print ("")

print ("In test_generator ")
for cls in range(len (test_generator.class_indices)):
    print(selectedClasses[cls],":\t",list(test_generator.classes).count(cls))

"""# Auxilary Functions for ploting images"""

def plots(ims, figsize = (22,22), rows=4, interp=False, titles=None, maxNum = 9):
    if type(ims[0] is np.ndarray):
        ims = np.array(ims).astype(np.uint8)
        if(ims.shape[-1] != 3):
            ims = ims.transpose((0,2,3,1))

    f = plt.figure(figsize=figsize)
    #cols = len(ims) //rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    cols = maxNum // rows if maxNum % 2 == 0 else maxNum//rows + 1
    #for i in range(len(ims)):
    for i in range(maxNum):
        sp = f.add_subplot(rows, cols, i+1)
        sp.axis('Off')
        if titles is not None:
            sp.set_title(titles[i], fontsize=20)
        plt.imshow(ims[i], interpolation = None if interp else 'none')

"""# Plot some train data"""

train_generator.reset()
imgs, labels = next(train_generator) # Use next(train_generator) to get the next batch of data
                                     # Alternatively, you can use train_generator.__next__()

#print(labels)

labelNames=[]
labelIndices=[np.where(r==1)[0][0] for r in labels]
#print(labelIndices)

for ind in labelIndices:
    for labelName,labelIndex in train_generator.class_indices.items():
        if labelIndex == ind:
            #print (labelName)
            labelNames.append(labelName)

#labels

#plots images with labels within jupyter notebook
import matplotlib.pyplot as plt #

def plots(ims, figsize = (22,22), rows=4, interp=False, titles=None, maxNum = 9):
    if type(ims[0] is np.ndarray):
        ims = np.array(ims).astype(np.uint8)
        if(ims.shape[-1] != 3):
            ims = ims.transpose((0,2,3,1))

    f = plt.figure(figsize=figsize)
    #cols = len(ims) //rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    cols = maxNum // rows if maxNum % 2 == 0 else maxNum//rows + 1
    #for i in range(len(ims)):
    for i in range(maxNum):
        sp = f.add_subplot(rows, cols, i+1)
        sp.axis('Off')
        if titles is not None:
            sp.set_title(titles[i], fontsize=20)
        plt.imshow(ims[i], interpolation = None if interp else 'none')

#Atutomatic rename with epoch number and val accuracy:
#filepath="checkpoints/weights-improvement-epeoch-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5"



modelName= "InceptionTutorial"
#save the best weights over the same file with the model name

#filepath="checkpoints/"+modelName+"_bestweights.hdf5"
filepath=modelName+"_bestweights.keras" # Added .keras extension
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

"""# Create model by Transfer Learning from InceptionV3"""

base_model = InceptionV3(weights='imagenet',
                                include_top=False,
                                input_shape=(224, 224,3))
base_model.trainable = False

x = base_model.output
x = keras.layers.GlobalAveragePooling2D()(x)

x = Dropout(0.5)(x)

predictions = Dense(len(selectedClasses), activation='softmax')(x)


model = Model(base_model.input, predictions)


model.summary()

from keras.applications import ResNet50


base_model = ResNet50(weights='imagenet',
                      include_top=False,
                      input_shape=(224, 224, 3))


base_model.trainable = False

x = base_model.output
x = keras.layers.GlobalAveragePooling2D()(x)


x = Dropout(0.5)(x)


predictions = Dense(len(selectedClasses), activation='softmax')(x)


model = Model(inputs=base_model.input, outputs=predictions)

model.summary()

"""# Usage of callbacks

https://keras.io/callbacks/


A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training.


## History

keras.callbacks.History()

Callback that records events into a History object.

This callback is automatically applied to every Keras model.
***The History object gets returned by the fit method of models.***


## ModelCheckpoint

***keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)***


Save the model after every epoch.


filepath can contain named formatting options, which will be filled the value of epoch and keys in logs (passed in on_epoch_end).


For example: if filepath is weights.{epoch:02d}-{val_loss:.2f}.hdf5, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.

### Arguments

***filepath:*** string, path to save the model file.

*** monitor:*** quantity to monitor.

***verbose:**** verbosity mode, 0 or 1.

***save_best_only:*** if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten.


***mode:**** one of {auto, min, max}.

***If save_best_only=True,**** the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc.

***In auto mode,*** the direction is automatically inferred from the name of the monitored quantity.

***save_weights_only:*** if True, then only the model's weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)).

***period:*** Interval (number of epochs) between checkpoints.

### Example:

***Atutomatic rename with epoch number and val accuracy:***

filepath="checkpoints/weights-improvement-epeoch-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5"

checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')

callbacks_list = [checkpoint]


## EarlyStopping

***keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)***

Stop training when a monitored quantity has stopped improving.

### Arguments

***monitor:*** quantity to be monitored.

***min_delta:*** minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.

***patience:*** number of epochs with no improvement after which training will be stopped.

***verbose:*** verbosity mode.

***mode:*** one of {auto, min, max}. **In min mode,** training will stop when the quantity monitored has stopped decreasing; **in max mode** it will stop when the quantity monitored has stopped increasing; **in auto mode,** the direction is automatically inferred from the name of the monitored quantity.

***baseline:*** Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline.

***restore_best_weights:*** whether to restore model weights from the epoch with the best value of the monitored quantity. **If False,** the model weights obtained at the last step of training are used.







"""

modelName= "InceptionTutorial"


filepath=modelName+"_bestweights.keras"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

"""# Compile the model"""

model.compile(Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

"""# Train the model

## Set up fit_generator
https://keras.io/models/model/

fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)

Trains the model on data generated batch-by-batch by a Python generator (or an instance of Sequence).

The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.

The use of keras.utils.Sequence guarantees the ordering and guarantees the single use of every input per epoch when using use_multiprocessing=True.

### Arguments

#### generator:
A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either
* a tuple (inputs, targets)
* a tuple (inputs, targets, sample_weights).
This tuple (a single output of the generator) makes a single batch. Therefore, all arrays in this tuple must have the same length (equal to the size of this batch). Different batches may have different sizes. For example, the last batch of the epoch is commonly smaller than the others, if the size of the dataset is not divisible by the batch size. The generator is expected to loop over its data indefinitely. An epoch finishes when steps_per_epoch batches have been seen by the model.

#### steps_per_epoch:
Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. ***It should typically be equal to the number of samples of your dataset divided by the batch size***. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.

#### epochs:
Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. Note that in conjunction with initial_epoch, epochs is to be understood as "final epoch". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.

#### verbose:
Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.

#### callbacks:
List of keras.callbacks.Callback instances. List of callbacks to apply during training. See callbacks.
validation_data: This can be either

* a generator or a Sequence object for the validation data
* tuple (x_val, y_val)
* tuple (x_val, y_val, val_sample_weights)
on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.

#### validation_steps:
Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. ***It should typically be equal to the number of samples of your validation dataset divided by the batch size.*** Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.

#### class_weight:
Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to "pay more attention" to samples from an under-represented class.

#### max_queue_size:
Integer. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.

#### workers:
Integer. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread.

#### use_multiprocessing:
Boolean. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.

#### shuffle:
Boolean. Whether to shuffle the order of the batches at the beginning of each epoch. Only used with instances of Sequence (keras.utils.Sequence). Has no effect when steps_per_epoch is not None.
initial_epoch: Integer. Epoch at which to start training (useful for resuming a previous training run).

### Returns

#### A History object.
Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).

### Calculate steps_per_epoch and validation_steps For fit_generator
Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. ***It should typically be equal to the number of samples of your dataset divided by the batch size.*** Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.
"""

stepsPerEpoch= (train_generator.samples+ (batchSize-1)) // batchSize
print("stepsPerEpoch: ", stepsPerEpoch)

validationSteps=(validation_generator.samples+ (batchSize-1)) // batchSize
print("validationSteps: ", validationSteps)


#validationSteps=(test_generator.samples+ (batchSize-1)) // batchSize
#print("validationSteps: ", validationSteps)

"""## Train
Run more epochs for increasing the accuracy. For example:

**epochs = 30**
"""

# Update ModelCheckpoint callback to track 'val_accuracy' and use the .keras file extension
checkpoint = ModelCheckpoint(filepath='best_model.keras',  # Changed to .keras
                             monitor='val_accuracy',
                             save_best_only=True)

callbacks_list = [checkpoint]  # Add the callback to the list

# Calculate steps per epoch based on dataset size and batch size
steps_per_epoch = len(train_generator)  # Or len(train_data) // batch_size
validation_steps = len(validation_generator)  # Or len(validation_data) // batch_size

!pip install tensorflow
!pip install keras

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator # Changed the import path to use tensorflow.keras.preprocessing.image

# ... your existing code for model definition and data generators ...

# 1. Double-check validation data:
#    - Ensure that `validation_generator` is correctly set up and points to your validation data.
#    - Verify that the validation data directory contains images and is not empty.
#    - Print a batch of validation data to check its format and content:

for data_batch, labels_batch in validation_generator:
    print('data batch shape:', data_batch.shape)
    print('labels batch shape:', labels_batch.shape)
    break

# 2. Simplify the validation process:
#    - Temporarily remove any custom metrics or callbacks that might be causing issues.
#    - Try training with a small subset of the validation data to see if that works.

# 3. Update TensorFlow and Keras:
#    - Ensure you have the latest versions of TensorFlow and Keras installed.
#    - You can update them using:
#        !pip install --upgrade tensorflow keras

# If the issue persists, please provide the following information:
#    - The code for your model definition.
#    - The code for creating `train_generator` and `validation_generator`.
#    - The content of your training and validation data directories.

# Steps per epoch and validation steps based on the number of images
steps_per_epoch = train_generator.samples // train_generator.batch_size
validation_steps = validation_generator.samples // validation_generator.batch_size

# Train the model using fit
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=10,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=callbacks_list,
    verbose=1
)

"""## Show Training History
We can plot the accuracy and loss values for each epoch using the history object as follows.
"""

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy']) # Changed 'acc' to 'accuracy'
plt.plot(history.history['val_accuracy']) # Changed 'val_acc' to 'val_accuracy'
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'Validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

"""
```

"""